{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e29636cc",
   "metadata": {},
   "source": [
    "# AI APPS SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0709831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-play-scraper in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: pandas in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: textblob in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (4.58.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: click in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\users\\test\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install google-play-scraper pandas numpy scikit-learn matplotlib seaborn wordcloud nltk textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5113bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL LIBRARIES LOADED SUCCESSFULLY\n",
      "Analysis Date: 2025-12-18 19:03:06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Web Scraping\n",
    "from google_play_scraper import app, Sort, reviews\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Statistical Analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency, f_oneway, ttest_ind, mannwhitneyu\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, mean_absolute_error,\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    classification_report, confusion_matrix, roc_auc_score, roc_curve,\n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "\n",
    "# Download NLTK data\n",
    "for resource in ['punkt', 'stopwords', 'wordnet', 'averaged_perceptron_tagger']:\n",
    "    nltk.download(resource, quiet=True)\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print(\"ALL LIBRARIES LOADED SUCCESSFULLY\")\n",
    "print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22698c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÄPP configure : 18\n",
      "countires : 9\n",
      "target reviews : 10000\n"
     ]
    }
   ],
   "source": [
    "# ai app configuration\n",
    "AI_APPS_CONFIG = {\n",
    "    'gemini': {\n",
    "        'app_id'    : 'com.google.android.apps.bard',\n",
    "        'name'      : 'Google Gemini AI',\n",
    "        'company'   : 'Google',\n",
    "        'category'  : 'Conversational/multimodal LLM',\n",
    "        'color'     : '#4285f4'\n",
    "        },\n",
    "    'chatgpt': {\n",
    "        'app_id'    : 'com.openai.chatgpt',\n",
    "        'name'      : 'ChatGPT',\n",
    "        'company'   : 'OpenAI',\n",
    "        'category'  : 'Conversational LLM',\n",
    "        'color'     : '#000000'\n",
    "    },\n",
    "    'claude': {\n",
    "        'app_id'    : 'com.anthropic.claude',\n",
    "        'name'      : 'ClaudeAI',\n",
    "        'company'   : 'Anthropic',\n",
    "        'category'  : 'Conversational LLM',\n",
    "        'color'     : '#D97757'\n",
    "    },\n",
    "    'grok': {\n",
    "        'app_id'    : 'ai.x.grok',\n",
    "        'name'      : 'Grok',\n",
    "        'company'   : 'xAI Corporation',\n",
    "        'category'  : 'Conversational/Humorius LLM',\n",
    "        'color'     : '#333333'\n",
    "    },\n",
    "    'Copilot': {\n",
    "        'app_id'    : 'com.microsoft.copilot',\n",
    "        'name'      : 'Microsoft Copilot: AI Chat',\n",
    "        'company'   : 'Microsoft Corporation',\n",
    "        'category'  : 'Intergrative/Conversational LLM',\n",
    "        'color'     : '#F25022'\n",
    "    },\n",
    "    'perplexity': {\n",
    "        'app_id'    : 'ai.perplexity.app.android',\n",
    "        'name'      : 'Perplexity - Ask Anything',\n",
    "        'company'   :'Perplexity AI, inc.',\n",
    "        'category'  : 'Search/Answer Enggine LLM',\n",
    "        'color'     : '#22B8CF'\n",
    "    },\n",
    "    'Poe': {\n",
    "        'app_id'    : 'com.quora.poe',\n",
    "        'name'      : 'Poe - Fast AI Chat',\n",
    "        'company'   : 'Quora, Inc',\n",
    "        'category'  : 'Aggregator/Bot Hosting',\n",
    "        'color'     : '#582696'\n",
    "    },\n",
    "    'Qwen': {\n",
    "        'app_id'    : 'ai.qwenlm.chat.android',\n",
    "        'name'      : 'Qwen Char',\n",
    "        'company'   : 'Alibaba Cloud',\n",
    "        'category'  : 'Conversational LLM (CN)',\n",
    "        'color'     : '#4D6BFE'\n",
    "    },\n",
    "    'Deepseek': {\n",
    "        'app_id'    : 'com.deepseek.chat',\n",
    "        'name'      : 'Deepseek - AI Assistant',\n",
    "        'company'   : 'Deepseek AI',\n",
    "        'category'  : 'Conversational/Coding LLM',\n",
    "        'color'     : '#4D6BFE'\n",
    "    },\n",
    "    'Otterai': {\n",
    "        'app_id'    : 'com.ainote.flow',\n",
    "        'name'      : 'Otter: AI Meeting Notes',\n",
    "        'company'   : 'AISense Inc',\n",
    "        'category'  : 'Transcription/Productivity',\n",
    "        'color'     : '#353D57'\n",
    "    },\n",
    "    'Blaxboxai': {\n",
    "        'app_id'    : 'com.blackbox.ai',\n",
    "        'name'      : 'BlackBox AI & Code Char',\n",
    "        'company'   : 'Blackbox AI',\n",
    "        'category'  : 'Coding Assistant/Developer',\n",
    "        'color'     : '#111111'\n",
    "    },\n",
    "    'Meta': {\n",
    "        'app_id'    : 'com.facebook.stella',\n",
    "        'name'      : 'Meta AI - Vibes & AI Glasses',\n",
    "        'company'   : 'Meta Platforms, Inc.',\n",
    "        'category'  : 'Conversational/Intergrated Reality',\n",
    "        'color'     : '#0064E0'\n",
    "    },\n",
    "    'characterai': {\n",
    "        'app_id'    : 'ai.character.app',\n",
    "        'name'      : 'Character.ai',\n",
    "        'company'   : 'Character.ai',\n",
    "        'category'  : 'Roleplay/Entertainment LLM',\n",
    "        'color'     : '#007AFF'  \n",
    "    },\n",
    "    'pi': {\n",
    "        'app_id'    : 'ai.inflection.pi',\n",
    "        'name'      : 'Pi, your personal AI',\n",
    "        'company'   : 'Inflection AI',\n",
    "        'category'  : 'Emotional Support/Personal Assistant',\n",
    "        'color'     : '#F4EBD0'  \n",
    "    },\n",
    "    'grammarly': {\n",
    "        'app_id'    : 'com.grammarly.android.keyboard',\n",
    "        'name'      : 'Grammarly - AI Writing',\n",
    "        'company'   : 'Grammarly, Inc.',\n",
    "        'category'  : 'Writing Assistant/Correction',\n",
    "        'color'     : '#15C39A'  \n",
    "    },\n",
    "    'deepl': {\n",
    "        'app_id'    : 'com.deepl.mobiletranslator',\n",
    "        'name'      : 'DeepL Translate',\n",
    "        'company'   : 'DeepL SE',\n",
    "        'category'  : 'AI Translation',\n",
    "        'color'     : '#0F2B46' \n",
    "    },\n",
    "    'socratic': {\n",
    "        'app_id'    : 'com.google.socratic',\n",
    "        'name'      : 'Socratic by Google',\n",
    "        'company'   : 'Google',\n",
    "        'category'  : 'Education/Homework Helper',\n",
    "        'color'     : '#FF6D00'  \n",
    "    },\n",
    "    'leonardo': {\n",
    "        'app_id'    : 'ai.leonardo.app',\n",
    "        'name'      : 'Leonardo.ai - Image Generator',\n",
    "        'company'   : 'Leonardo.Ai',\n",
    "        'category'  : 'Image Generation/Art',\n",
    "        'color'     : '#9B51E0'  \n",
    "    }\n",
    "}\n",
    "\n",
    "# scraping configuration\n",
    "SCRAPING_CONFIG = {\n",
    "    'countries': ['us', 'gb', 'in', 'id', 'jp', 'br', 'fr', 'ca', 'au'],\n",
    "    'reviews_per_app' : 10000,\n",
    "    'language': 'en'\n",
    "}\n",
    "\n",
    "# dir \n",
    "for dir_name in ['data', 'models', 'output', 'reports']:\n",
    "    os.makedirs(dir_name, exist_ok=True)\n",
    "\n",
    "print(f\"ÄPP configure : {len(AI_APPS_CONFIG)}\")\n",
    "print(f\"countires : {len(SCRAPING_CONFIG['countries'])}\")\n",
    "print(f\"target reviews : {SCRAPING_CONFIG['reviews_per_app']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c93ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playstore scraper done\n"
     ]
    }
   ],
   "source": [
    "# collecting data\n",
    "class PlayStoreScraper:\n",
    "    \"\"\"\n",
    "    Production-grade Google Play Store scraper.\n",
    "    \n",
    "    Features:\n",
    "    - Multi-country scraping\n",
    "    - Error handling and retry logic\n",
    "    - Progress tracking\n",
    "    - App metadata collection\n",
    "    \"\"\"\n",
    "    def __init__(self, apps_config: Dict, scraping_config: Dict):\n",
    "        self.apps = apps_config\n",
    "        self.countries = scraping_config['countries']\n",
    "        self.reviews_per_app = scraping_config['reviews_per_app']\n",
    "        self.language = scraping_config['language']\n",
    "    \n",
    "\n",
    "    def get_app_info(self, app_id: str, country: str = 'us') -> Optional[Dict]:\n",
    "        \"\"\"Fetch metadata\"\"\"\n",
    "        try:\n",
    "            info = app(app_id, lang=self.language, country=country)\n",
    "            return {\n",
    "                'app_id': app_id,\n",
    "                'title': info.get('title'),\n",
    "                'rating': info.get('score'),\n",
    "                'reviews_count': info.get('reviews'),\n",
    "                'installs': info.get('installs'),\n",
    "                'developer': info.get('developer'),\n",
    "                'last_updated': info.get('updated'),\n",
    "                'version': info.get('version'),\n",
    "                'size': info.get('size'),\n",
    "                'content_rating': info.get('contentRating')\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {app_id} : {e}\")\n",
    "            return None\n",
    "\n",
    "    def scrape_reviews(self, app_key: str, app_config: Dict) -> pd.DataFrame:\n",
    "        \"\"\"Scrape reviews for a single app from multiple countries\"\"\"\n",
    "        all_reviews = []\n",
    "        reviews_per_country = self.reviews_per_app // len(self.countries)\n",
    "\n",
    "        for country in self.countries:\n",
    "            try:\n",
    "                result, _ = reviews(\n",
    "                    app_config['app_id'],\n",
    "                    lang=self.language,\n",
    "                    country=country,\n",
    "                    sort=Sort.NEWEST,\n",
    "                    count=reviews_per_country\n",
    "                )\n",
    "\n",
    "                for r in result:\n",
    "                    r['app_key']    = app_key \n",
    "                    r['app_name']   = app_config['name']      \n",
    "                    r['company']    = app_config['company']   \n",
    "                    r['category']   = app_config['category']\n",
    "                    r['country']    = country.upper() \n",
    "\n",
    "                all_reviews.extend(result)\n",
    "            except:\n",
    "                print(f\" {country.upper()} : {e}\")\n",
    "            \n",
    "        return pd.DataFrame(all_reviews)\n",
    "\n",
    "    def scrape_all(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Scrape all apps and return reviews + app info\"\"\"\n",
    "        print(\"colleccting data.....\")\n",
    "\n",
    "        all_reviews = []\n",
    "        app_info_list = []\n",
    "\n",
    "        for app_key, app_config in tqdm(self.apps.items(), desc=\"Scraping apps\"):\n",
    "            print(f\"\\n {app_config['name']}.....\")\n",
    "\n",
    "            # getr app info\n",
    "            info = self.get_app_info(app_config['app_id'])\n",
    "            if info:\n",
    "                info['app_key'] = app_key\n",
    "                info['company'] = app_config['company']\n",
    "                app_info_list.append(info)\n",
    "                print(f\" rating : {info['rating']:.2f} | reviews : {info['reviews_count']:,}\")\n",
    "            \n",
    "            # get review\n",
    "            df_reviews = self.scrape_reviews(app_key, app_config)\n",
    "            if len(df_reviews) > 0:\n",
    "                all_reviews.append(df_reviews)\n",
    "                print(f\"   collected: {len(df_reviews):,} reviews\")\n",
    "        \n",
    "        df_all_reviews = pd.concat(all_reviews, ignore_index=True) if all_reviews else pd.DataFrame()\n",
    "        df_app_info = pd.DataFrame(app_info_list)\n",
    "\n",
    "        print(\"Collection completed\")\n",
    "        \n",
    "\n",
    "        return df_all_reviews, df_app_info\n",
    "\n",
    "print(\"playstore scraper done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6bca6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colleccting data.....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Google Gemini AI.....\n",
      " rating : 4.54 | reviews : 103,221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:   6%|▌         | 1/18 [00:13<03:53, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " ChatGPT.....\n",
      " rating : 4.75 | reviews : 131,240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  11%|█         | 2/18 [00:27<03:39, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " ClaudeAI.....\n",
      " rating : 4.57 | reviews : 5,224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  17%|█▋        | 3/18 [00:41<03:27, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Grok.....\n",
      " rating : 4.88 | reviews : 24,173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  22%|██▏       | 4/18 [00:52<03:00, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Microsoft Copilot: AI Chat.....\n",
      " rating : 4.75 | reviews : 28,195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  28%|██▊       | 5/18 [01:04<02:40, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Perplexity - Ask Anything.....\n",
      " rating : 4.66 | reviews : 11,078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  33%|███▎      | 6/18 [01:16<02:27, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Poe - Fast AI Chat.....\n",
      "Error fetching com.quora.poe : App not found(404).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  39%|███▉      | 7/18 [01:18<01:39,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Qwen Char.....\n",
      " rating : 4.04 | reviews : 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  44%|████▍     | 8/18 [01:28<01:31,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 7,272 reviews\n",
      "\n",
      " Deepseek - AI Assistant.....\n",
      " rating : 4.15 | reviews : 5,519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  50%|█████     | 9/18 [01:40<01:32, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Otter: AI Meeting Notes.....\n",
      "Error fetching com.ainote.flow : App not found(404).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  56%|█████▌    | 10/18 [01:43<01:02,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BlackBox AI & Code Char.....\n",
      "Error fetching com.blackbox.ai : App not found(404).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  61%|██████    | 11/18 [01:45<00:43,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Meta AI - Vibes & AI Glasses.....\n",
      " rating : 4.65 | reviews : 5,251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  67%|██████▋   | 12/18 [01:56<00:45,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Character.ai.....\n",
      " rating : 3.66 | reviews : 66,378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  72%|███████▏  | 13/18 [02:09<00:45,  9.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Pi, your personal AI.....\n",
      " rating : 3.72 | reviews : 922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  78%|███████▊  | 14/18 [02:21<00:39, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Grammarly - AI Writing.....\n",
      " rating : 4.17 | reviews : 25,570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  83%|████████▎ | 15/18 [02:33<00:31, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " DeepL Translate.....\n",
      " rating : 4.66 | reviews : 2,688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  89%|████████▉ | 16/18 [02:45<00:22, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Socratic by Google.....\n",
      "Error fetching com.google.socratic : App not found(404).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps:  94%|█████████▍| 17/18 [02:56<00:11, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   collected: 9,999 reviews\n",
      "\n",
      " Leonardo.ai - Image Generator.....\n",
      "Error fetching ai.leonardo.app : App not found(404).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping apps: 100%|██████████| 18/18 [02:59<00:00,  9.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection completed\n",
      "saved to data/raw_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "scraper = PlayStoreScraper(AI_APPS_CONFIG, SCRAPING_CONFIG)\n",
    "df_raw, df_app_info = scraper.scrape_all()\n",
    "\n",
    "# save raw data\n",
    "df_raw.to_csv('data/raw_reviews.csv', index=False)\n",
    "df_app_info.to_csv('data/app_info.csv', index=False)\n",
    "print(\"saved to data/raw_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5714deea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape : (137259, 16)\n",
      "\n",
      " columns : ['reviewId', 'userName', 'userImage', 'content', 'score', 'thumbsUpCount', 'reviewCreatedVersion', 'at', 'replyContent', 'repliedAt']...\n",
      "review per app\n",
      "app_name\n",
      "Google Gemini AI                9999\n",
      "ChatGPT                         9999\n",
      "ClaudeAI                        9999\n",
      "Grok                            9999\n",
      "Microsoft Copilot: AI Chat      9999\n",
      "Perplexity - Ask Anything       9999\n",
      "Deepseek - AI Assistant         9999\n",
      "Meta AI - Vibes & AI Glasses    9999\n",
      "Character.ai                    9999\n",
      "Pi, your personal AI            9999\n",
      "Grammarly - AI Writing          9999\n",
      "DeepL Translate                 9999\n",
      "Socratic by Google              9999\n",
      "Qwen Char                       7272\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape : {df_raw.shape}\")\n",
    "print(f\"\\n columns : {list(df_raw.columns)[:10]}...\")\n",
    "print(f\"review per app\")\n",
    "print(df_raw['app_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "132026a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_rows: 137259\n",
      "missing_content_count: 0\n",
      "empty_removed: 15579\n",
      "validations: {'rating_range_valid': True, 'no_null_app_names': True, 'dates_valid': True}\n",
      "final_rows: 121680\n",
      "row_removed: 15579\n",
      "clean dataset : 121,680 reviews\n"
     ]
    }
   ],
   "source": [
    "# cleaning\n",
    "class DataCleaner:\n",
    "    def __init__(self, df:pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.stats = {'initial_rows' : len(df)}\n",
    "    \n",
    "    def remove_duplicates(self) -> 'DataCleaner':\n",
    "        before = len(self.df)\n",
    "        self.df = self.df.drop_duplicates(subset=['reviewId'], keep='first')\n",
    "        self.stats['duplicates_removed'] = before - len(self.df)\n",
    "        return self\n",
    "    \n",
    "    def handle_missing_values(self)-> 'DataCleaner':\n",
    "        self.df['content'] = self.df['content'].fillna('')\n",
    "        self.df['thumbsUpCount'] = self.df['thumbsUpCount'].fillna(0).astype(int)\n",
    "        self.df['replyContent'] = self.df['replyContent'].fillna('')\n",
    "        self.stats['missing_content_count'] = (self.df['content'] == '').sum()\n",
    "        return self\n",
    "    \n",
    "    def filter_empty_reviews(self, min_chars : int = 5 ) -> 'DataCleaner':\n",
    "        before = len(self.df)\n",
    "        self.df = self.df[self.df['content'].str.len() >= min_chars]\n",
    "        self.stats['empty_removed'] = before - len(self.df)\n",
    "        return self\n",
    "\n",
    "    def standardize_columns(self) -> 'DataCleaner':\n",
    "        column_map = {\n",
    "            'reviewId' : 'review_id',\n",
    "            'userName' : 'user_name',\n",
    "            'content' : 'review_text',\n",
    "            'score' : 'rating',\n",
    "            'thumbsUpCount' : 'thumbs_up',\n",
    "            'at' : 'review_date',\n",
    "            'replyContent' : 'developer_reply',\n",
    "            'repliedAt' : 'reply_date',\n",
    "            'appVersion' : 'app_version'\n",
    "        }\n",
    "\n",
    "        cols_to_keep = [c for c in column_map.keys() if c in self.df.columns]\n",
    "        cols_to_keep.extend(['app_key', 'app_name', 'company', 'category', 'country'])\n",
    "\n",
    "        self.df = self.df[[c for c in cols_to_keep if c in self.df.columns]]\n",
    "        self.df = self.df.rename(columns={k: v for k, v in column_map.items() if k in self.df.columns})\n",
    "\n",
    "        self.df['review_date'] =pd.to_datetime(self.df['review_date'])\n",
    "        self.df['rating'] = self.df['rating'].astype(int)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def validate(self) -> 'DataCleaner':\n",
    "        \"\"\"Run data quality validations.\"\"\"\n",
    "        validations = {\n",
    "            'rating_range_valid': self.df['rating'].between(1, 5).all(),\n",
    "            'no_null_app_names': self.df['app_name'].notna().all(),\n",
    "            'dates_valid': self.df['review_date'].notna().all()\n",
    "        }\n",
    "        self.stats['validations'] = validations\n",
    "        return self\n",
    "    \n",
    "    def get_result(self) -> Tuple[pd.DataFrame, Dict]:\n",
    "        self.stats['final_rows'] = len(self.df)\n",
    "        self.stats['row_removed'] = self.stats['initial_rows'] - self.stats['final_rows']\n",
    "        return self.df, self.stats\n",
    "    \n",
    "cleaner = DataCleaner(df_raw)\n",
    "df, cleaning_stats = (\n",
    "    cleaner\n",
    "    .handle_missing_values()\n",
    "    .filter_empty_reviews(min_chars=5)\n",
    "    .standardize_columns()\n",
    "    .validate()\n",
    "    .get_result()\n",
    ")\n",
    "\n",
    "for key, value in cleaning_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "print(f\"clean dataset : {len(df):,} reviews\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54808ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FE:\n",
    "    def __init__(self,df : pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.stop_word = set(stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.feature_group = {}\n",
    "\n",
    "        def add_temporal_features(self) -> 'FE':\n",
    "            dt = self.df['review_date']\n",
    "            self.df['year'] = dt.dt.year\n",
    "            self.df['month'] = dt.dt.month\n",
    "            self.df['day'] = dt.dt.day\n",
    "            self.df['dayofweek'] = dt.dt.dayofweek\n",
    "            self.df['dayofweek_name'] = dt.dt.day_name()\n",
    "            self.df['hour'] = dt.dt.hour\n",
    "            self.df['quarter'] = dt.dt.quarter\n",
    "            self.df['is_weekend'] = dt.dt.dayofweek.isin([5,6]).astype(int)\n",
    "            self.df['is_month_start'] = dt.dt.is_month_start.astype(int)\n",
    "            self.df['is_month_end'] = dt.dt.is_month_end.astype(int)\n",
    "            self.df['days_since_review'] = (datetime.now() - dt).dt.days\n",
    "\n",
    "            self.feature_group['temporal'] = 11\n",
    "            return self\n",
    "        \n",
    "        def add_text_length_features(self) -> 'FE':\n",
    "            text = self.df['review_text']\n",
    "\n",
    "            self.df['char_count'] = text.str.len()\n",
    "            self.df['word_count'] = text.str.split().str.len()\n",
    "            self.df['sentence_count'] = text.str.count(r'.!?+').clip(lower=1)\n",
    "            self.df['avg_word_length'] = self.df['char_count'] / (self.df['word_count'] + 1)\n",
    "            self.df['avg_sentence_lenght'] = self.df['word_count'] / self.df['sentence_count']\n",
    "            self.df['unique_word_count'] = text.apply(lambda x: len(set(str(x).lower().split)))\n",
    "            self.df['unique_word_ratio'] = self.df['unique_word_count'] / (self.df['word_count'] + 1)\n",
    "\n",
    "            # lenght categories\n",
    "            self.df['length_category'] = pd.cut(\n",
    "                self.ddf['word_count'],\n",
    "                bins=[0, 10, 30, 100, 1000],\n",
    "                labels=['very_short', 'short', 'medium', 'long']\n",
    "            )\n",
    "\n",
    "            self.feature_group['text_length'] = 8\n",
    "            return self\n",
    "        \n",
    "        def add_text_pattern_features(self) -> 'FE':\n",
    "            text = self.df['review_text']\n",
    "\n",
    "            self.df['exclamation_count'] = text.str.count('!') \n",
    "            self.df['question_count'] =  text.str.count(r'\\?')\n",
    "            self.df['uppercase_count'] = text.apply(lambda x: sum(1 for c in str(x) if c.isupper()))\n",
    "            self.df['uppercase_ratio'] = self.df['uppercase_count'] / (self.df['char_count'] + 1)\n",
    "            self.df['digit_count'] =  text.str.count(r'\\d')\n",
    "            self.df['special_chat_count'] = text.str.count(r'[^a-zA-Z0-9\\s]')\n",
    "            self.df['emoji_count'] = text.apply(lambda x: len(re.findall(r'[\\U0001F600-\\U0001F64F]', str(x))))\n",
    "            self.df['has_url'] = text.str.contains(r'http[s]?://', regex=True).astype(int)\n",
    "            self.df['has_email'] = text.str.contains(r'\\S+@\\S+', regex=True).astype(int)\n",
    "            self.df['has_mention'] = text.str.contains(r'@\\w+', regex=True).astype(int)\n",
    "            self.df['has_hastag'] = text.str.contains(r'#\\w+', regrex=True).astype(int)\n",
    "            self.df['all_caps_word_count'] = text.apply(lambda x: sum(1 for w in str(x).split()if w.isupper() and len(w) > 1))\n",
    "\n",
    "            self.feature_groups['text_patterns'] = 12\n",
    "            return self\n",
    "        \n",
    "        # sentiment features\n",
    "        def add_sentiment_features(self) -> 'FE':\n",
    "            \"\"\"Calculate sentiment scores using texblob\"\"\"\n",
    "            def get_sentiment(text):\n",
    "                try:\n",
    "                    blob = TextBlob(str(text))\n",
    "                    return blob.sentiment.polarity, blob.sentiment.subjectivity\n",
    "                except:\n",
    "                    return 0.0, 0.0\n",
    "            \n",
    "            sentiments = self.df['review_text'].apply(get_sentiment)\n",
    "            self.df['polarity'] = sentiments.apply(lambda x: x[0])\n",
    "            self.df['subjectivity'] = sentiments.apply(lambda x: x[1])\n",
    "\n",
    "            # derived sentiment features\n",
    "            self.df['polarity_abs'] = self.df['polarity'].abs()\n",
    "            self.df['is_positive_polarity'] = (self.df['polarity'] > 0).astypes(int)\n",
    "            self.df['is_negative_polarity'] = (self.df['polarity'] < 0).astypes(int)\n",
    "            self.df['is_neutral_polarity'] = (self.df['polarity'] == 0).astypes(int)\n",
    "            self.df['is_subjective'] = (self.df['subjectivity'] >  0.5).astypes(int)\n",
    "            self.df['polarity_subjectivity_ratio'] = self.df['polarity_abs'] / (self.df['subjectivity'] + 0.01)\n",
    "\n",
    "            self.features_groups['sentiment'] = 8\n",
    "            return self\n",
    "        \n",
    "        # label features\n",
    "        def add_label_features(self) -> 'FE':\n",
    "            \"\"\"Create target label and derived features\"\"\"\n",
    "            # sentiment from rating\n",
    "            self.df['sentiment_label'] = self.df['rating'].apply(\n",
    "                lambda x: 'positive' if x >= 4 else ('negative' if x <= 2 else 'neutral')\n",
    "            )\n",
    "            self.df['sentiment_binary'] = (self.df['rating'] >= 4).astype(int)\n",
    "            self.df['sentiment_ternary'] = self.df['rating'].apply(\n",
    "                lambda x:2 if x >= 4 else (0 if x <=2 else 1)\n",
    "            )\n",
    "\n",
    "            # rating based features\n",
    "            self.df['is_extreme_rating'] = self.df['rating'].isin([1,5]).astype(int)\n",
    "            self.df['is_perfect_rating'] = self.df(['rating'] == 5).astype(int)\n",
    "            self.df['is_perfect_rating'] = self.df(['rating'] == 1).astype(int)\n",
    "\n",
    "            self.feature_group['labels'] = 6\n",
    "            return self\n",
    "        \n",
    "        # text cleaning\n",
    "        def add_cleaned_text(self) -> 'FE':\n",
    "            def clean_text(text):\n",
    "                text = str(text).lower()\n",
    "                text = re.sub(r'http\\S+|www\\S+', '', text) # url\n",
    "                text = re.sub(r'\\S+@\\S+', '', text) # email\n",
    "                text = re.sub(r'[a-zA-Z\\s]', '', text) # specia; char\n",
    "                text = ''.join(text.split()) # nornmalize whitespace\n",
    "                return text\n",
    "            \n",
    "            def remove_stepword(text):\n",
    "                words = text.split()\n",
    "                return ' '.join([self.lemmatizer.lemmatize(w) for w in words])\n",
    "            \n",
    "            def lemmatize(text):\n",
    "                words = text.split()\n",
    "                return ' '.join([self.lemmatizer.lemmatize(w) for w in words])\n",
    "            \n",
    "            self.df['clean_text'] = self.df['review_text'].apply(clean_text)\n",
    "            self.df['text_no_stopwords'] = self.df['clean_text'].apply(remove_stepword)\n",
    "            self.df['processed_text'] = self.df['text_no_stopwords'].apply(lemmatize)\n",
    "            self.df['processed_word_count'] = self.df['processed_text'].str.split().str.len()\n",
    "\n",
    "            self.feature_groups['text_cleaning'] = 4\n",
    "            return self\n",
    "        \n",
    "        # keyword feature \n",
    "        def add_keyword_features(self) -> 'FE':\n",
    "            \"\"\"Counting sentiment-realted keywords\"\"\"\n",
    "            positive_word = ['love', 'beautifull', 'helpfull', 'amazing',\n",
    "                             'great', '5/10', 'fantastic', 'useful', 'best',\n",
    "                             'awesome', 'excellent', 'perfect', 'superb']\n",
    "            negative_word = ['bitch', 'stupid', 'annoying', 'hate', 'terrible', 'worst',\n",
    "                              'bad','useless', 'trash', 'garbage', 'disappointing', 'slow', 'crash',\n",
    "                         'bug', 'broken', 'waste', 'poor', 'annoying', 'frustrating' ]\n",
    "            ai_words = ['ai', 'gpt', 'llm', 'rag', 'agi', 'model', 'response', 'answer', 'conversation',\n",
    "                   'accurate', 'smart', 'intelligent', 'understand', 'language']\n",
    "            \n",
    "        def count_words(text, word_list):\n",
    "            text_lower = str(text).lower()\n",
    "            return sum(1 for w in word_list if w in text_lower )\n",
    "        \n",
    "        self.df['positive_word_count'] = self.df['review_text'].apply(lambda x: count_words(x, positive_word))\n",
    "        self.df['negative_word_count'] = self.df['review_text'].apply(lambda x: count_words(x. negative_word))\n",
    "        self.df['ai_word_count'] = self.df['review_Text'].apply(lambda x: count_words(x, ai_word) )\n",
    "        self.df['keyword_sentiment_score'] = self.df['review_Text'] - self.df['negative_word_count']\n",
    "        self.df['has_positive_words'] = (self.df['positive_Word_count'] > 0).astype(int)\n",
    "        self.df['has_negative_words'] = (self.df['negative_Word_count'] > 0).astype(int)\n",
    "\n",
    "        self.feature_group['keywords'] = 6\n",
    "        return self\n",
    "        \n",
    "\n",
    "            \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
